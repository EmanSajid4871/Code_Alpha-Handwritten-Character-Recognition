{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import argparse, os, platform, numpy as np, matplotlib.pyplot as plt\n",
        "from typing import Tuple\n",
        "import torch, torch.nn as nn, torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "#Args\n",
        "def get_args():\n",
        "    p = argparse.ArgumentParser()\n",
        "    p.add_argument(\"--dataset\", type=str, default=\"mnist\",\n",
        "                   choices=[\"mnist\",\"emnist-letters\"],\n",
        "                   help=\"Choose MNIST (10 classes) or EMNIST letters (26 classes)\")\n",
        "    p.add_argument(\"--epochs\", type=int, default=6)\n",
        "    p.add_argument(\"--batch_size\", type=int, default=128)\n",
        "    p.add_argument(\"--lr\", type=float, default=1e-3)\n",
        "    p.add_argument(\"--augment\", action=\"store_true\", help=\"Apply light augmentation\")\n",
        "    p.add_argument(\"--out\", type=str, default=\"outputs_task3\")\n",
        "    # In Colab, we parse known args and ignore the rest\n",
        "    return p.parse_known_args()[0]\n",
        "\n",
        "#Data loading\n",
        "def get_transforms(augment: bool):\n",
        "    base = [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
        "    if augment:\n",
        "        aug = [transforms.RandomAffine(degrees=8, translate=(0.08,0.08), scale=(0.95,1.05))]\n",
        "        return transforms.Compose(aug + base)\n",
        "    return transforms.Compose(base)\n",
        "\n",
        "def load_data(dataset: str, batch_size: int, augment: bool, pin_memory: bool, num_workers: int) -> Tuple[DataLoader, DataLoader, int]:\n",
        "    root = \"./data\"\n",
        "    if dataset == \"mnist\":\n",
        "        num_classes = 10\n",
        "        train_ds = datasets.MNIST(root, train=True, download=True, transform=get_transforms(augment))\n",
        "        test_ds  = datasets.MNIST(root, train=False, download=True, transform=get_transforms(False))\n",
        "    else:  # emnist-letters\n",
        "        # labels can be 1..26 or remapped to 0..25 depending on torchvision version\n",
        "        num_classes = 26\n",
        "        train_ds = datasets.EMNIST(root, split=\"letters\", train=True, download=True, transform=get_transforms(augment))\n",
        "        test_ds  = datasets.EMNIST(root, split=\"letters\", train=False, download=True, transform=get_transforms(False))\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_ds, batch_size=batch_size, shuffle=True,\n",
        "        num_workers=num_workers, pin_memory=pin_memory\n",
        "    )\n",
        "    test_loader  = DataLoader(\n",
        "        test_ds, batch_size=batch_size, shuffle=False,\n",
        "        num_workers=num_workers, pin_memory=pin_memory\n",
        "    )\n",
        "    return train_loader, test_loader, num_classes\n",
        "\n",
        "#Model\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes: int):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),  # 28x28 -> 14x14\n",
        "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2), # 14x14 -> 7x7\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64*7*7, 128), nn.ReLU(), nn.Dropout(0.25),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "#Train / Evaluate\n",
        "def train_one_epoch(model, loader, criterion, opt, device):\n",
        "    model.train()\n",
        "    total, correct, loss_sum = 0, 0, 0.0\n",
        "    for x,y in loader:\n",
        "        x,y = x.to(device), y.to(device)\n",
        "        opt.zero_grad()\n",
        "        logits = model(x)\n",
        "        loss = criterion(logits, y)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        loss_sum += loss.item() * x.size(0)\n",
        "        pred = logits.argmax(1)\n",
        "        correct += (pred == y).sum().item()\n",
        "        total += y.size(0)\n",
        "    return loss_sum/total, correct/total\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total, correct, loss_sum = 0, 0, 0.0\n",
        "    y_true, y_pred = [], []\n",
        "    for x,y in loader:\n",
        "        x,y = x.to(device), y.to(device)\n",
        "        logits = model(x)\n",
        "        loss = criterion(logits, y)\n",
        "        loss_sum += loss.item() * x.size(0)\n",
        "        pred = logits.argmax(1)\n",
        "        correct += (pred == y).sum().item()\n",
        "        total += y.size(0)\n",
        "        y_true.extend(y.cpu().numpy().tolist())\n",
        "        y_pred.extend(pred.cpu().numpy().tolist())\n",
        "    return loss_sum/total, correct/total, np.array(y_true), np.array(y_pred)\n",
        "\n",
        "def plot_confusion(cm, class_names, path):\n",
        "    fig, ax = plt.subplots(figsize=(6,6))\n",
        "    im = ax.imshow(cm, cmap=\"Blues\")\n",
        "    ax.set_title(\"Confusion Matrix\")\n",
        "    ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\")\n",
        "    ax.set_xticks(range(len(class_names))); ax.set_yticks(range(len(class_names)))\n",
        "    ax.set_xticklabels(class_names, rotation=90); ax.set_yticklabels(class_names)\n",
        "    for (i,j),v in np.ndenumerate(cm):\n",
        "        ax.text(j, i, str(v), ha=\"center\", va=\"center\", fontsize=7)\n",
        "    fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
        "    plt.tight_layout(); plt.savefig(path, dpi=150); plt.close(fig)\n",
        "\n",
        "#Main\n",
        "def main():\n",
        "    args = get_args()\n",
        "    os.makedirs(args.out, exist_ok=True)\n",
        "\n",
        "    # Device + DataLoader settings (fixes your warning)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    use_pin_memory = (device.type == \"cuda\")  # only pin if GPU is present\n",
        "    # Windows often behaves better with 0 workers inside PyCharm\n",
        "    is_windows = (platform.system().lower() == \"windows\")\n",
        "    num_workers = 0 if is_windows else 2\n",
        "\n",
        "    print(f\"Using device: {device} | pin_memory={use_pin_memory} | num_workers={num_workers}\")\n",
        "\n",
        "    train_loader, test_loader, num_classes = load_data(\n",
        "        args.dataset, args.batch_size, args.augment, use_pin_memory, num_workers\n",
        "    )\n",
        "\n",
        "    model = SimpleCNN(num_classes).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    opt = optim.Adam(model.parameters(), lr=args.lr)\n",
        "\n",
        "    best_acc, best_path = 0.0, os.path.join(args.out, f\"{args.dataset}_best.pt\")\n",
        "\n",
        "    for epoch in range(1, args.epochs+1):\n",
        "        tr_loss, tr_acc = train_one_epoch(model, train_loader, criterion, opt, device)\n",
        "        te_loss, te_acc, y_true, y_pred = evaluate(model, test_loader, criterion, device)\n",
        "        if te_acc > best_acc:\n",
        "            best_acc = te_acc\n",
        "            torch.save(model.state_dict(), best_path)\n",
        "        print(f\"Epoch {epoch:02d} | train_loss {tr_loss:.4f} acc {tr_acc:.4f} | \"\n",
        "              f\"val_loss {te_loss:.4f} acc {te_acc:.4f}\")\n",
        "\n",
        "    print(f\"Best val accuracy: {best_acc:.4f}; saved: {best_path}\")\n",
        "\n",
        "    # Reload best for final reporting\n",
        "    model.load_state_dict(torch.load(best_path, map_location=device))\n",
        "    _, _, y_true, y_pred = evaluate(model, test_loader, criterion, device)\n",
        "\n",
        "    # Build class names robustly based on labels we actually saw\n",
        "    classes = np.unique(np.concatenate([y_true, y_pred]))\n",
        "    if args.dataset == \"mnist\":\n",
        "        class_names = [str(int(c)) for c in classes]\n",
        "    else:\n",
        "        # EMNIST letters can be 0..25 or 1..26; map to a..z accordingly\n",
        "        if classes.min() == 1:  # 1..26\n",
        "            class_names = [chr(ord('a') + int(c) - 1) for c in classes]\n",
        "        else:  # 0..25\n",
        "            class_names = [chr(ord('a') + int(c)) for c in classes]\n",
        "\n",
        "    print(\"\\nClassification report (macro F1 included):\")\n",
        "    print(classification_report(y_true, y_pred, labels=classes, target_names=class_names, digits=4))\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=classes)\n",
        "    cm_path = os.path.join(args.out, f\"{args.dataset}_confusion_matrix.png\")\n",
        "    plot_confusion(cm, class_names, cm_path)\n",
        "    print(f\"Saved confusion matrix â†’ {cm_path}\")\n",
        "\n",
        "# Call the main function directly in the Colab cell or as a script\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGz2Rspm8so8",
        "outputId": "ede79243-19ef-4c4c-8511-3c20725a90b8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu | pin_memory=False | num_workers=2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.91M/9.91M [00:00<00:00, 103MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28.9k/28.9k [00:00<00:00, 39.5MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.65M/1.65M [00:00<00:00, 35.6MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.54k/4.54k [00:00<00:00, 4.36MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | train_loss 0.1981 acc 0.9396 | val_loss 0.0405 acc 0.9875\n",
            "Epoch 02 | train_loss 0.0582 acc 0.9823 | val_loss 0.0413 acc 0.9855\n",
            "Epoch 03 | train_loss 0.0443 acc 0.9860 | val_loss 0.0306 acc 0.9900\n",
            "Epoch 04 | train_loss 0.0340 acc 0.9896 | val_loss 0.0268 acc 0.9905\n",
            "Epoch 05 | train_loss 0.0274 acc 0.9913 | val_loss 0.0236 acc 0.9927\n",
            "Epoch 06 | train_loss 0.0224 acc 0.9925 | val_loss 0.0247 acc 0.9925\n",
            "Best val accuracy: 0.9927; saved: outputs_task3/mnist_best.pt\n",
            "\n",
            "Classification report (macro F1 included):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9889    0.9980    0.9934       980\n",
            "           1     0.9965    1.0000    0.9982      1135\n",
            "           2     0.9866    0.9961    0.9913      1032\n",
            "           3     0.9970    0.9921    0.9945      1010\n",
            "           4     0.9959    0.9929    0.9944       982\n",
            "           5     0.9866    0.9933    0.9899       892\n",
            "           6     0.9968    0.9854    0.9911       958\n",
            "           7     0.9961    0.9854    0.9907      1028\n",
            "           8     0.9918    0.9908    0.9913       974\n",
            "           9     0.9901    0.9921    0.9911      1009\n",
            "\n",
            "    accuracy                         0.9927     10000\n",
            "   macro avg     0.9926    0.9926    0.9926     10000\n",
            "weighted avg     0.9927    0.9927    0.9927     10000\n",
            "\n",
            "Saved confusion matrix â†’ outputs_task3/mnist_confusion_matrix.png\n"
          ]
        }
      ]
    }
  ]
}